{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation \n",
    "Maximum likelihood estimation is the method which directly gives MVU (Minimum variance Unbiased) estimator of the natural parameter of a probability distribution. \n",
    "<ul>\n",
    "    <li>This is a point estimate method</li>\n",
    "    <li>98% of the cases it gives you MVU estimator. </li>\n",
    "    <li>It is a <b>Deterministic approximation inference method</b></li>\n",
    "</ul>\n",
    "\n",
    "Likelihood function is also known as PDF which tells a probability of occurance of particular value is a sample. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have many probability distribution function lke:\n",
    "- Normal Distribution \n",
    "- Binomial Distribution\n",
    "- Uniform Distribution\n",
    "- Poisson Distribution\n",
    "- Gamma Distribution \n",
    "and many more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum likelihood estimation uses $-\\log_e$ Likelihood function. Because We have to find the maximum value of likelihood function.<br>\n",
    "\n",
    "Let's take example of Normal Distribution:\n",
    "So, probability Density function of normal distribution is given by:\n",
    "$$P(X=x) = \\frac{1}{2\\pi\\sigma} e^{\\frac{(x-\\mu)}{2\\sigma^2}}$$\n",
    "\n",
    "In this formula, we have two natural parameters. Natural parameters are the scale value which change the graph.\n",
    "To find the values for natural parameters, We have to calculate formula for every natural parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to find maximum likeliood function for any Probability Distribution. \n",
    "- We assume that we took a sample from particular probability distributed population with some unknown natural paramters. \n",
    "- We are also assuming that sample has n observation which are IID(Independent & Identically distributed)\n",
    "<br><br>According to the IID assumption:\n",
    "So, after assuming Identically Distributed we will get:\n",
    "$$L(P(X = x)) = P(X = x_1 \\cap X = x_2\\cap ... \\cap X = x_n)$$ \n",
    "After assuming Independently distributed we will get:\n",
    "$$L(P(X = x)) = P(X = x_1) . P(X = x_2) . .... . P(X = x_n)$$\n",
    "\n",
    "Now, we want to find such values of $\\hat{\\mu}$ and $\\hat{\\sigma}$. Such that, $L(\\hat{\\mu}, \\hat{\\sigma})$ reaches to its maximum value.\n",
    "We have to find the Global Maxima for all the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the MVU estimator for $\\hat{\\mu}$\n",
    "\n",
    "Let's expand the formula. \n",
    "$$L(\\mu, \\sigma) = \\frac{1}{2\\pi\\sigma} e^{\\frac{(x_0-\\mu)}{2\\sigma^2}}  \\frac{1}{2\\pi\\sigma} e^{\\frac{(x_1-\\mu)}{2\\sigma^2}}. \\frac{1}{2\\pi\\sigma} e^{\\frac{(x_2-\\mu)}{2\\sigma^2}}. ... . \\frac{1}{2\\pi\\sigma} e^{\\frac{(x_N-\\mu)}{2\\sigma^2}}$$\n",
    "\n",
    "$$L(\\hat{\\mu}) = {\\bigg(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\bigg)}^N  e^ {\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}$$\n",
    "Applying $log$ on $L(\\hat{\\mu})$\n",
    "$$log_e(L(\\hat{\\mu})) = log_e\\bigg({{\\bigg(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\bigg)}^N  e^ {\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}}\\bigg)$$\n",
    "$$log_e(L(\\hat{\\mu})) = log_e\\bigg({{\\bigg(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\bigg)}^N\\bigg) + log_e\\bigg(e^ {\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}}\\bigg)$$\n",
    "\n",
    "$$log_e(L(\\hat{\\mu})) = Nlog_e\\big({{\\frac{1}{\\sqrt{2\\pi}\\sigma}}\\big) +{\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}}$$\n",
    "\n",
    "$$log_e(L(\\hat{\\mu})) = \\bigg[ - Nlog_e\\big({\\sqrt{2\\pi}\\sigma\\big) -{\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}} \\bigg]$$\n",
    "\n",
    "Applying negative sign both side. \n",
    "$$- log_e(L(\\hat{\\mu})) = \\bigg[ Nlog_e\\big({\\sqrt{2\\pi}\\sigma\\big) +{\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}} \\bigg]$$\n",
    "\n",
    "With respect to $\\mu$ take partial differentiation.\n",
    "$$-log_e(L(\\hat{\\mu})) = \\frac{\\partial}{\\partial \\mu}Nlog_e{\\sqrt{2\\pi}\\sigma + \\frac{\\partial}{\\partial \\mu}{\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu) ^ 2}{2 \\sigma^2}}}$$\n",
    "\n",
    "$$-log_e(L(\\hat{\\mu})) = N\\frac{\\partial}{\\partial \\mu}{\\sqrt{2\\pi}\\sigma +  2\\frac{\\partial}{\\partial \\mu}{\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu)}{2 \\sigma^2}}}$$\n",
    "\n",
    "\n",
    "$$-log_e(L(\\hat{\\mu})) = 0 +  \\frac{\\partial}{\\partial \\mu}{\\frac{\\Sigma_{i = 1}^{N} (x_i - \\mu)}{\\sigma^2}}$$\n",
    "\n",
    "Equating to 0, and sending denominator.\n",
    "$$0 = \\frac{\\partial}{\\partial \\mu}{\\Sigma_{i = 1}^{N} (x_i - \\mu)}$$\n",
    "\n",
    "$$ = \\Sigma_{i = 1}^{N} (x_i - \\mu)$$\n",
    "\n",
    "We can also write it as \n",
    "$$ = (x_1 - \\mu) + (x_2 - \\mu) + (x_3 - \\mu) + ... + (x_N - \\mu) $$\n",
    "\n",
    "$$ = (x_1 + x_2 + x_3 + ... + x_N) N\\mu$$\n",
    "\n",
    "$$ = (\\Sigma_{i = 1}^{N} x_i)  N\\mu$$\n",
    "\n",
    "$$N\\mu = (\\Sigma_{i = 1}^{N} $$\n",
    "\n",
    "$$E[\\hat{\\mu}_{ML}] = \\frac{\\Sigma_{i = 1}^{N} x_i}{N} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can find it for other natural parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to modify the likelihood function to log likelihood function because our likelihood function was non-convex which will create problem in reaching to *global maxima* and therefore converting our function into log likelihood. it become convex. Thereby maing it easier to reach global maximum. But still we can't maximize our log likelihood function. So, we add negative sign. on the left hand side on our function. There by making it ultimately log likelihood function. \n",
    "\n",
    "So, after solving for one natural parameter.\n",
    "Like in normal Distribution we have $\\mu$ and $\\sigma$. \n",
    "\n",
    "MVU estimator for $\\mu$ is given by:\n",
    "$$E\\big[\\hat{\\mu}_{ML}\\big] = \\frac{\\Sigma_{i=1}^{n}x_i}{n}$$\n",
    "\n",
    "MVU estimator for $\\sigma^2$ is given by:\n",
    "$$E\\big[(X - E[\\hat{\\mu}_{ML}])^2\\big] = \\frac{\\Sigma_{i=0}^N(x_i - E[\\hat{\\mu}_{ML}])^2}{N}$$\n",
    "\n",
    "Similarly, MVU estimator for $\\sigma$ is given by:\n",
    "$$E\\big[\\sqrt{(X - E[\\hat{\\mu}_{ML}])^2}\\big] = \\sqrt{\\frac{\\Sigma_{i=0}^N(x_i - E[\\hat{\\mu}_{ML}])^2}{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are trying \n",
    "\n",
    "$$E[\\hat{\\mu}] = \\frac{\\Sigma_{i=1}^N x_i}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X = x_i) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e ^{\\big({- \\frac{(x-\\mu)^2}{2\\sigma^2}}\\big)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proof that MVU estimator for natural parameter of normal distribution are given above using Sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the population mean and standard deviation\n",
    "pop_mean = 50\n",
    "pop_std = 10\n",
    "pop_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i am taking a population which is normally distributed with the mean value of 50 and std of 10\n",
    "population = np.random.normal(loc = pop_mean, scale = pop_std, size = pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the population graph.\n",
    "plt.hist(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing sample size and number of samples\n",
    "sample_size = 20\n",
    "total_sample_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54.83582156, 40.84218422, 41.11797858, 62.12288566, 66.05684896,\n",
       "        55.6874517 , 52.10859451, 46.49552312, 53.52003244, 51.87643087,\n",
       "        35.6955966 , 24.98229273, 47.49248757, 49.816361  , 23.46256214,\n",
       "        62.66945462, 49.32967107, 45.69328339, 51.38595118, 41.11709557],\n",
       "       [53.96024219, 53.27794113, 77.11837852, 36.06956165, 42.02959074,\n",
       "        46.06509963, 64.27664604, 53.95079542, 39.86226691, 65.23816756,\n",
       "        44.1770795 , 40.01364   , 61.08731487, 46.28163401, 52.65667593,\n",
       "        55.61586688, 53.94269758, 53.33906236, 53.83633492, 49.97377589]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking random sample from the population initialized above.\n",
    "\n",
    "samples = np.random.choice(population, size = (total_sample_size, sample_size))\n",
    "samples[:2] # Printing first 2 random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now, we initalize a population with some mean and standard deviation.<br>\n",
    "Then we take choose random samples from the population. \n",
    "\n",
    "Now, i am going to calculate the natural parameters of normal distribution using the solved formula. \n",
    "\n",
    "So, first let's calculate for $\\mu$. We also says it as $E[\\hat{\\mu}_{ML}]$ which is given by:\n",
    "$$E\\big[\\hat{\\mu}_{ML}\\big] = \\frac{\\Sigma_{i=1}^{n}x_i}{n}$$\n",
    "\n",
    "\n",
    "It is the statistical mean. So we can directly use numpy function with axis = 1. Because, we have to calculate it for individual sample. If we don't give it then it will consider for whole array as one. \n",
    "```python\n",
    "numpy.mean(samples, axis = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.81542538, 52.13863859, 51.50132897, 51.03296668, 47.64065145,\n",
       "       49.60224327, 48.45299692, 50.62801393, 49.44153578, 50.30267145,\n",
       "       47.25216635, 52.54999784, 53.21303093, 50.23381882, 51.26336717,\n",
       "       50.0989625 , 52.33914681, 51.3817989 , 50.63852773, 50.38484925,\n",
       "       47.21832601, 50.62981853, 54.24188559, 51.35930666, 51.23110943,\n",
       "       54.18306604, 48.14849942, 49.53681326, 51.77177567, 50.84940995,\n",
       "       50.68246841, 46.53301089, 49.43151467, 51.02828756, 50.43736919,\n",
       "       51.49283106, 51.85963065, 47.18511135, 50.51733891, 47.72865331,\n",
       "       51.784477  , 50.26710336, 53.5128665 , 46.28115876, 50.51079133,\n",
       "       50.10407972, 51.31476823, 52.15070395, 49.30139087, 54.59921354,\n",
       "       49.30624045, 45.89840201, 54.21264187, 50.82011046, 50.38534998,\n",
       "       47.88127354, 46.89183681, 54.04106357, 48.60561371, 50.25333675,\n",
       "       49.31259594, 47.73627094, 49.88099678, 52.70086258, 51.20869462,\n",
       "       50.50865009, 49.73797257, 50.58189292, 50.98370387, 50.84812055,\n",
       "       51.33270896, 45.56446028, 49.39833254, 47.8537714 , 49.89308748,\n",
       "       50.10386619, 51.89084475, 47.83871315, 48.19308112, 51.05256117,\n",
       "       50.06135734, 48.94788389, 49.18433008, 49.17211048, 50.47466984,\n",
       "       50.0094528 , 48.66597089, 45.94154864, 49.12611772, 50.72482661,\n",
       "       46.72715604, 48.43250277, 50.63469125, 50.60741425, 51.99236535,\n",
       "       47.48847032, 48.43927273, 48.62868289, 52.24399975, 49.11098782])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_means = np.mean(samples, axis = 1)\n",
    "sample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  6., 10., 10., 14., 26., 15.,  8.,  2.,  5.]),\n",
       " array([45.56446028, 46.4679356 , 47.37141093, 48.27488626, 49.17836158,\n",
       "        50.08183691, 50.98531224, 51.88878756, 52.79226289, 53.69573822,\n",
       "        54.59921354]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the sampling distribution for the mean value. \n",
    "\n",
    "plt.hist(sample_means, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here graph for that distribution is quite normal. So, to calculate the best estmated value for $\\mu$. We can take the mean value of all **sample means** because as we know, that the highest buldge in normal distribution is come to mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0533578706017"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimated_mean_val = np.mean(sample_means)\n",
    "best_estimated_mean_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the error between the real value for the natural parameter and estimated value. And say it as Bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias between the real and estimated values: 0.053\n"
     ]
    }
   ],
   "source": [
    "bias = best_estimated_mean_val - pop_mean\n",
    "print ('Bias between the real and estimated values: %.3f'%(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see,\n",
    "Estimated value for the natural parameter $\\mu$ is having very low bais.\n",
    "\n",
    "Similarly, let's check for natural parameter $\\sigma$ which is given by:\n",
    "$$E\\big[\\sqrt{(X - E[\\hat{\\mu}_{ML}])^2}\\big] = \\sqrt{\\frac{\\Sigma_{i=0}^N(x_i - E[\\hat{\\mu}_{ML}])^2}{N}}$$\n",
    "\n",
    "I am using the same sample to estimate $\\sigma$\n",
    "\n",
    "As, we know $\\sigma$ is the statistical standard deviation which is:\n",
    "$$s =  \\sqrt{\\frac{\\Sigma_{i=1}^{N}(x_i - \\bar{x}) ^ 2}{N}}$$\n",
    "\n",
    "We can use numpy function to calculate standard deviation. \n",
    "```python\n",
    "np.std(sample, axis = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stds = np.std(samples, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5., 12., 24., 22., 19., 12.,  6.]),\n",
       " array([ 6.11211424,  7.15731095,  8.20250766,  9.24770438, 10.29290109,\n",
       "        11.3380978 , 12.38329451, 13.42849122]),\n",
       " <a list of 7 Patch objects>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the sample standard deviations\n",
    "plt.hist(sample_stds, bins = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimated std: 9.765\n"
     ]
    }
   ],
   "source": [
    "## Calculate the mean value to find the best estimated value.\n",
    "\n",
    "best_estimated_std = np.mean(sample_stds)\n",
    "print ('Best estimated std: %.3f'%best_estimated_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias between the real and estimated values: -0.235\n"
     ]
    }
   ],
   "source": [
    "# Checking for bias\n",
    "bias_std = best_estimated_std - pop_std\n",
    "print ('Bias between the real and estimated values: %.3f'%(bias_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can find best estimators for any distributions natural parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
